{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Green AI - EPSCI - 2024**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/green_ai_espci/blob/main/opt_cnn/Green_AI_ESPCI_base_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that supports high FP16 compute scaling (e.g the Tesla T4), it is advised to change the mixed_precision parameter in the prediction to \"FP16C_FP32A\".  \n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing CIANNA installation\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIFAR-10**\n",
        "\n",
        "CIFAR-10 is a lightweihgt dataset, which comprises 60000 images of 32x32 pixels labeled into 10 classes. 50000 images are used to train supervised learning models, with 5000 examples for each class, and 10000 images are used for testing trained models, with 1000 examples for each class."
      ],
      "metadata": {
        "id": "gd2waB3JYNkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading and visualizing the data\n"
      ],
      "metadata": {
        "id": "kULtlVy8Y5UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a work directory and download the default aux_fct.py file that contain the image augmentation policy.\n",
        "You can edit this file by opening the left panel, navigating to /content/green_ai_opt_cnn/ and double clicking on the aux_fct.py\n",
        "\n",
        "Note that modifications of this file are only saved for the current session. You can download you modified file to save it for a later session. In that case you can upload a modified aux_fct.py file instead of loading the default one from the GitHub.\n",
        "\n",
        "If you have indent error after modifying the file, it is certainly cause by the different \"tabulation\" caracter used by Colab. By selecting multiple lines of codes around your error you should be able to distinguish which line has the wrong tabulation character."
      ],
      "metadata": {
        "id": "TzB778Q0EX_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir /content/green_ai_opt_cnn/\n",
        "cd /content/green_ai_opt_cnn/\n",
        "\n",
        "#Get the default aux_fct.py file from the GitHub.\n",
        "wget https://github.com/Deyht/green_ai_espci/raw/main/opt_cnn/aux_fct.py"
      ],
      "metadata": {
        "id": "mjcrByRgYof3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/green_ai_opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "\n",
        "init_data_gen(0)\n",
        "\n",
        "print(\"\\nOrdered validation examples\")\n",
        "create_val_batch()\n",
        "\n",
        "print(\"Create visualization of the validation dataset\")\n",
        "visual_val(8,4)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "-PsyIg0sZmSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell display the saved .jpg representation of the validation dataset."
      ],
      "metadata": {
        "id": "xSDTjqYUHDjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/green_ai_opt_cnn/\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = Image.open(\"val_mosaic.jpg\")\n",
        "plt.figure(figsize=(8,4), dpi=200)\n",
        "plt.imshow(im)\n",
        "plt.gca().axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xwExEJTXZygB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a network\n",
        "\n",
        "You can modify whatever you find necessary to optimize the mixed accuracy/efficiency/size metric. The only rule is to not use external data and outside pretrained model (you can still reload a model you trained here and modify part of its architecture to not restart from scratch every time you change something)."
      ],
      "metadata": {
        "id": "6ZeV1bvjRS4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/green_ai_opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "from aux_fct import *\n",
        "import gc, sys, glob\n",
        "\n",
        "#Comment to access system wide install\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = create_train_batch()\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images_per_iter, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "\n",
        "total_iter = 900 #Larger architecture are likely to require more iterations\n",
        "nb_iter_per_augm = 1 #Increase if augmentation is slower that training on one iteration\n",
        "if(nb_iter_per_augm > 1):\n",
        "\tshuffle_frequency = 1\n",
        "else:\n",
        "\tshuffle_frequency = 0\n",
        "\n",
        "load_iter = 0 #Used to select the net_save file from which the training must be restarted\n",
        "\n",
        "start_iter = int(load_iter / nb_iter_per_augm)\n",
        "\n",
        "#The batch size can be adapted to reduce the RAM footprint, but it is likely to affect the reachable accuracy\n",
        "#The mixed precision can be switched to FP16C_FP32A to speed up training on T4 GPUs,\n",
        "#but it can induce vanishing or exploding gradients\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class,\n",
        "\t\tbias=0.1, b_size=16, comp_meth='C_CUDA', dynamic_load=1,\n",
        "\t\tmixed_precision=\"FP32C_FP32A\", adv_size=30)\n",
        "\n",
        "init_data_gen()\n",
        "\n",
        "input_val, targets_val = create_val_batch()\n",
        "cnn.create_dataset(\"VALID\", nb_val, input_val[:,:], targets_val[:,:])\n",
        "cnn.create_dataset(\"TEST\", nb_val, input_val[:,:], targets_val[:,:])\n",
        "del (input_val, targets_val)\n",
        "gc.collect()\n",
        "\n",
        "input_data, targets = create_train_batch()\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_iter, input_data[:,:], targets[:,:])\n",
        "\n",
        "if(load_iter > 0):\n",
        "\t#Load a model save file based on the default naming scheme\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_iter, load_iter, bin=1)\n",
        "\t#You can change the file path to load a renamed saved model; e.g.:\n",
        "\t#cnn.load(\"my_model.dat\", load_iter, bin=1)\n",
        "else:\n",
        "\t#Create a new network structure to train from scratch\n",
        "\t#See the CIANNA API description for a list of available layers and there parameters\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=8 , padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=16, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.5)\n",
        "\tcnn.dense(nb_neurons=128, activation=\"RELU\", drop_rate=0.2)\n",
        "\tcnn.dense(nb_neurons=nb_class, strict_size=1, activation=\"SMAX\")\n",
        "\n",
        "for run_iter in range(start_iter,int(total_iter/nb_iter_per_augm)):\n",
        "\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\n",
        "\t#See the CIANNA API description for a list and descroption of available keywords\n",
        "\tcnn.train(nb_iter=nb_iter_per_augm, learning_rate=0.002, end_learning_rate=0.00003, shuffle_every=shuffle_frequency ,\\\n",
        "\t\t\t control_interv=20, confmat=1, momentum=0.9, lr_decay=0.0015, weight_decay=0.0005, save_every=20,\\\n",
        "\t\t\t silent=0, save_bin=1, TC_scale_factor=256.0)\n",
        "\n",
        "\tif(run_iter == start_iter):\n",
        "\t\tcnn.perf_eval()\n",
        "\n",
        "\tt.join()\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "MvRhvumeRWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate your model\n",
        "\n",
        "The following cell allow to evaluate the accuracy and compute performance of your model in inference mode. Always run the inference at least twice in a row to remove GPU startup effects from the compute time.\n",
        "\n",
        "The last cell compute the score from the inference result based on the reference model performance. Edit the corresponding Google Sheet to add your model result:  \n",
        "https://docs.google.com/spreadsheets/d/1kfTaaakPPD8Oa4YuzvYuMpFHZTKxBctc899s_E_U6iw/edit?usp=sharing"
      ],
      "metadata": {
        "id": "quIkFmK1TLUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/green_ai_opt_cnn/\n",
        "\n",
        "python3 - <<EOF 2>&1 | tee out.txt\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "from aux_fct import *\n",
        "import gc, time, sys, glob\n",
        "\n",
        "#Comment to access system wide install\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "load_epoch = 900\n",
        "\n",
        "#Change image test mode in aux_fct to change network resolution in all functions\n",
        "init_data_gen(test_mode=1)\n",
        "\n",
        "#Batch size does not affect the inference result, but larger batch size process faster.\n",
        "#Using FP16C_FP32A can sligtly reduce the accuracy, but it strongly accelerate computation.\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class,\n",
        "\tbias=0.1, b_size=16, comp_meth='C_CUDA', dynamic_load=1,\n",
        "\tmixed_precision=\"FP32C_FP32A\", adv_size=30, inference_only=1)\n",
        "\n",
        "#Compute on only half the validation set to reduce memory footprint\n",
        "input_test, targets_test = create_val_batch()\n",
        "cnn.create_dataset(\"TEST\", nb_val, input_test[:,:], targets_test[:,:])\n",
        "\n",
        "del (input_test, targets_test)\n",
        "gc.collect()\n",
        "\n",
        "if(load_epoch == 0):\n",
        "\t#If load epoch is 0, load the reference model instead\n",
        "\tif(not os.path.isfile(\"arch_ref_res32_err24.18_ms330.dat\")):\n",
        "\t\tos.system(\"wget https://share.obspm.fr/s/TnLePm62SjCg4s4/download/arch_ref_res32_err24.18_ms330.dat\")\n",
        "\tcnn.load(\"arch_ref_res32_err24.18_ms330.dat\", load_epoch, bin=1)\n",
        "else:\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch, load_epoch, bin=1)\n",
        "\n",
        "\n",
        "cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "cnn.forward(no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "end = time.perf_counter()\n",
        "\n",
        "cnn.perf_eval()\n",
        "\n",
        "compute_time = (end-start)*1000 #in miliseconds\n",
        "np.savetxt(\"compute_time.txt\", [compute_time])\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "oMM45xmgTgFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/green_ai_opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "\n",
        "load_epoch = 900\n",
        "\n",
        "init_data_gen(test_mode=1)\n",
        "input_test, targets_test = create_val_batch()\n",
        "score_eval(load_epoch)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "G5JkThlhRn6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
